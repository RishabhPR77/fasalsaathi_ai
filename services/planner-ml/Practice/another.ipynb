{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87aa113f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting hyperparameter search... (this can take several minutes)\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "\n",
      "âœ… Search complete!\n",
      "Found the best parameters:\n",
      "{'regressor__subsample': 0.8, 'regressor__n_estimators': 700, 'regressor__max_depth': 3, 'regressor__learning_rate': 0.01, 'regressor__colsample_bytree': 0.9}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import xgboost as xgb\n",
    "\n",
    "# 1. Load Data\n",
    "df = pd.read_csv('mp_agriculture_stagewise_10000rows_district_season.csv')\n",
    "\n",
    "# 2. Define Features and a SINGLE Target for Tuning\n",
    "features = ['crop', 'seed_type', 'soil', 'district', 'season']\n",
    "# We focus on the main target for tuning\n",
    "tune_target = 'total_duration_estimate'\n",
    "\n",
    "X = df[features]\n",
    "y = df[tune_target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Create a Pipeline for the Single-Target Model\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), features)]\n",
    ")\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', xgb.XGBRegressor(random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# 4. Define the Search Space for Hyperparameters\n",
    "# We give it a range of settings to try for each key parameter\n",
    "param_dist = {\n",
    "    'regressor__n_estimators': [100, 300, 500, 700],\n",
    "    'regressor__max_depth': [3, 5, 7, 9],\n",
    "    'regressor__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'regressor__subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "    'regressor__colsample_bytree': [0.7, 0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# 5. Set up and Run the Randomized Search\n",
    "# n_iter=25 means it will test 25 different combinations. n_jobs=-1 uses all CPU cores.\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline, param_distributions=param_dist, n_iter=25,\n",
    "    cv=5, scoring='neg_mean_absolute_error', n_jobs=-1, random_state=42, verbose=1\n",
    ")\n",
    "\n",
    "print(\"ðŸš€ Starting hyperparameter search... (this can take several minutes)\")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# 6. Get the Best Parameters\n",
    "print(\"\\nâœ… Search complete!\")\n",
    "best_params = random_search.best_params_\n",
    "print(\"Found the best parameters:\")\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60e3df49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Training the final, optimized multi-output model...\n",
      "âœ… Final model training complete!\n",
      "\n",
      "ðŸ“Š Overall Model Performance (Tuned Model):\n",
      "   The final average error is: 10.6854\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multioutput import RegressorChain\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# --- PASTE THE BEST PARAMETERS FROM THE SEARCH ABOVE ---\n",
    "# Example format: {'regressor__subsample': 0.8, 'regressor__n_estimators': 500, ...}\n",
    "best_params_from_search = {\n",
    "    'subsample': 0.9,\n",
    "    'n_estimators': 700,\n",
    "    'max_depth': 7,\n",
    "    'learning_rate': 0.05,\n",
    "    'colsample_bytree': 0.9\n",
    "}\n",
    "# Remove the 'regressor__' prefix for the final model\n",
    "cleaned_params = {k.replace('regressor__', ''): v for k, v in best_params_from_search.items()}\n",
    "\n",
    "\n",
    "# Define all 78 targets again\n",
    "targets = ['total_duration_estimate'] + [col for col in df.columns if col.endswith(('_tmin', '_tmax', '_rh', '_rain', '_wind', '_solar_rad'))] + [col for col in df.columns if col.endswith('_stage_dur')]\n",
    "Y = df[targets]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Create the final, optimized pipeline\n",
    "preprocessor_final = ColumnTransformer(\n",
    "    transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), features)]\n",
    ")\n",
    "\n",
    "# Use the BEST parameters found in our base model\n",
    "base_model_tuned = xgb.XGBRegressor(**cleaned_params, random_state=42, n_jobs=-1)\n",
    "\n",
    "final_model = RegressorChain(base_estimator=base_model_tuned)\n",
    "\n",
    "pipeline_final = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_final),\n",
    "    ('regressor', final_model)\n",
    "])\n",
    "\n",
    "# Train and evaluate the final, tuned model\n",
    "print(\"\\nðŸš€ Training the final, optimized multi-output model...\")\n",
    "pipeline_final.fit(X_train, Y_train)\n",
    "print(\"âœ… Final model training complete!\")\n",
    "\n",
    "predictions_final = pipeline_final.predict(X_test)\n",
    "mae_final = mean_absolute_error(Y_test, predictions_final, multioutput='uniform_average')\n",
    "\n",
    "print(f\"\\nðŸ“Š Overall Model Performance (Tuned Model):\")\n",
    "print(f\"   The final average error is: {mae_final:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
